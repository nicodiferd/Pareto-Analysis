{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Flora Chat Data Cleaning\n",
    "\n",
    "Robust data pipeline to properly parse and clean the flora-chats export.\n",
    "\n",
    "**Key challenges addressed:**\n",
    "- CSV contains embedded JSON with commas (breaks naive pandas parsing)\n",
    "- Input column contains both instructions AND data payloads\n",
    "- Need to separate user intent from structured data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "DATA_DIR = Path(\"../data\")\n",
    "RAW_FILE = DATA_DIR / \"flora-chats-01-09-26.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-load",
   "metadata": {},
   "source": [
    "## 1. Load Raw Data (Proper CSV Parsing)\n",
    "\n",
    "Using Python's csv module instead of pandas for accurate parsing of embedded JSON/quotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "load-data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 96 rows\n",
      "Columns: ['id', 'timestamp', 'name', 'userId', 'sessionId', 'release', 'version', 'environment', 'tags', 'input', 'output']\n",
      "\n",
      "Sample userId (should be clean UUID): c1d2a96d-da46-404b-97ed-ffcbd76f1dab\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>name</th>\n",
       "      <th>userId</th>\n",
       "      <th>sessionId</th>\n",
       "      <th>release</th>\n",
       "      <th>version</th>\n",
       "      <th>environment</th>\n",
       "      <th>tags</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>206abeb3502f897134951d0e9c989dbc</td>\n",
       "      <td>2026-01-09T17:04:42.739Z</td>\n",
       "      <td>flora-thinking</td>\n",
       "      <td>c1d2a96d-da46-404b-97ed-ffcbd76f1dab</td>\n",
       "      <td>chat-history_4410630c-cd0d-44cb-9177-878383aca50c</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>production</td>\n",
       "      <td>[\"askLLMAsync\",\"flora-thinking\",\"openai\",\"org-...</td>\n",
       "      <td>For work period @work_period:ef237015-9250-4b1...</td>\n",
       "      <td># Sprint Report: REBEL-2025 SP26  \\n2025-12-10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2bbde341c2c32604a8ea3095d490f68c</td>\n",
       "      <td>2026-01-09T17:00:42.509Z</td>\n",
       "      <td>flora-thinking</td>\n",
       "      <td>1927df39-3746-4a83-bf6d-527e91d72ee6</td>\n",
       "      <td>chat-history_ec79e713-967f-4c20-a0c2-f51fd694c7a2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>production</td>\n",
       "      <td>[\"flora-thinking\",\"org-7a24ea6d-262e-4e04-a1b6...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5afb40311aa5651533d87821df0bed21</td>\n",
       "      <td>2026-01-09T17:00:52.905Z</td>\n",
       "      <td>flora-thinking</td>\n",
       "      <td>1927df39-3746-4a83-bf6d-527e91d72ee6</td>\n",
       "      <td>chat-history_df8a1de7-b7fe-40db-a3b8-80fb57d5b860</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>production</td>\n",
       "      <td>[\"flora-thinking\",\"org-7a24ea6d-262e-4e04-a1b6...</td>\n",
       "      <td>Analyze the following data and provide a conci...</td>\n",
       "      <td>Key insights for work period STAR-2025 SP26 (1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>afc00d1fecece5bce4484e040aa921a7</td>\n",
       "      <td>2026-01-09T16:57:51.458Z</td>\n",
       "      <td>flora-thinking</td>\n",
       "      <td>c1d2a96d-da46-404b-97ed-ffcbd76f1dab</td>\n",
       "      <td>chat-history_12e07917-515a-462a-8f13-923eea51147f</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>production</td>\n",
       "      <td>[\"askLLMAsync\",\"flora-thinking\",\"openai\",\"org-...</td>\n",
       "      <td>tell me about this initiative</td>\n",
       "      <td># Initiative: Additional payment methods 2025 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00aa93e2a3edd0eede03b95874dcf279</td>\n",
       "      <td>2026-01-05T17:21:05.265Z</td>\n",
       "      <td>flora-thinking</td>\n",
       "      <td>c1d2a96d-da46-404b-97ed-ffcbd76f1dab</td>\n",
       "      <td>chat-history_498fb4ef-1603-43ec-bf54-97795a6bd067</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>production</td>\n",
       "      <td>[\"askLLMAsync\",\"flora-thinking\",\"openai\",\"org-...</td>\n",
       "      <td>provide sprint reto analysis for work period '...</td>\n",
       "      <td>Data retrieval was unsuccessful. You requested...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id                 timestamp            name  \\\n",
       "0  206abeb3502f897134951d0e9c989dbc  2026-01-09T17:04:42.739Z  flora-thinking   \n",
       "1  2bbde341c2c32604a8ea3095d490f68c  2026-01-09T17:00:42.509Z  flora-thinking   \n",
       "2  5afb40311aa5651533d87821df0bed21  2026-01-09T17:00:52.905Z  flora-thinking   \n",
       "3  afc00d1fecece5bce4484e040aa921a7  2026-01-09T16:57:51.458Z  flora-thinking   \n",
       "4  00aa93e2a3edd0eede03b95874dcf279  2026-01-05T17:21:05.265Z  flora-thinking   \n",
       "\n",
       "                                 userId  \\\n",
       "0  c1d2a96d-da46-404b-97ed-ffcbd76f1dab   \n",
       "1  1927df39-3746-4a83-bf6d-527e91d72ee6   \n",
       "2  1927df39-3746-4a83-bf6d-527e91d72ee6   \n",
       "3  c1d2a96d-da46-404b-97ed-ffcbd76f1dab   \n",
       "4  c1d2a96d-da46-404b-97ed-ffcbd76f1dab   \n",
       "\n",
       "                                           sessionId release version  \\\n",
       "0  chat-history_4410630c-cd0d-44cb-9177-878383aca50c                   \n",
       "1  chat-history_ec79e713-967f-4c20-a0c2-f51fd694c7a2                   \n",
       "2  chat-history_df8a1de7-b7fe-40db-a3b8-80fb57d5b860                   \n",
       "3  chat-history_12e07917-515a-462a-8f13-923eea51147f                   \n",
       "4  chat-history_498fb4ef-1603-43ec-bf54-97795a6bd067                   \n",
       "\n",
       "  environment                                               tags  \\\n",
       "0  production  [\"askLLMAsync\",\"flora-thinking\",\"openai\",\"org-...   \n",
       "1  production  [\"flora-thinking\",\"org-7a24ea6d-262e-4e04-a1b6...   \n",
       "2  production  [\"flora-thinking\",\"org-7a24ea6d-262e-4e04-a1b6...   \n",
       "3  production  [\"askLLMAsync\",\"flora-thinking\",\"openai\",\"org-...   \n",
       "4  production  [\"askLLMAsync\",\"flora-thinking\",\"openai\",\"org-...   \n",
       "\n",
       "                                               input  \\\n",
       "0  For work period @work_period:ef237015-9250-4b1...   \n",
       "1                                                      \n",
       "2  Analyze the following data and provide a conci...   \n",
       "3                      tell me about this initiative   \n",
       "4  provide sprint reto analysis for work period '...   \n",
       "\n",
       "                                              output  \n",
       "0  # Sprint Report: REBEL-2025 SP26  \\n2025-12-10...  \n",
       "1                                                     \n",
       "2  Key insights for work period STAR-2025 SP26 (1...  \n",
       "3  # Initiative: Additional payment methods 2025 ...  \n",
       "4  Data retrieval was unsuccessful. You requested...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def strip_quotes(val):\n",
    "    \"\"\"Remove surrounding quotes from a string value.\"\"\"\n",
    "    if isinstance(val, str):\n",
    "        # Strip leading/trailing whitespace first\n",
    "        val = val.strip()\n",
    "        # Remove surrounding quotes (handles \"\" and escaped quotes)\n",
    "        while len(val) >= 2 and val.startswith('\"') and val.endswith('\"'):\n",
    "            val = val[1:-1]\n",
    "        # Handle escaped quotes like \\\"\n",
    "        val = val.replace('\\\\\"', '\"')\n",
    "    return val\n",
    "\n",
    "def load_raw_csv(filepath):\n",
    "    \"\"\"Load CSV with proper handling of embedded quotes and JSON.\"\"\"\n",
    "    rows = []\n",
    "    columns = ['id', 'timestamp', 'name', 'userId', 'sessionId', \n",
    "               'release', 'version', 'environment', 'tags', 'input', 'output']\n",
    "    \n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        reader = csv.reader(f, quotechar='\"', doublequote=True)\n",
    "        header = next(reader)  # Skip header\n",
    "        \n",
    "        for row in reader:\n",
    "            row_data = {}\n",
    "            for i, col in enumerate(columns):\n",
    "                val = row[i] if i < len(row) else ''\n",
    "                # Strip surrounding quotes from each value\n",
    "                row_data[col] = strip_quotes(val)\n",
    "            rows.append(row_data)\n",
    "    \n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "df_raw = load_raw_csv(RAW_FILE)\n",
    "print(f\"Loaded {len(df_raw)} rows\")\n",
    "print(f\"Columns: {list(df_raw.columns)}\")\n",
    "print(f\"\\nSample userId (should be clean UUID): {df_raw['userId'].iloc[0]}\")\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-validate",
   "metadata": {},
   "source": [
    "## 2. Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "validate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA VALIDATION ===\n",
      "Total rows: 96\n",
      "Unique users (before validation): 13\n",
      "Unique sessions: 76\n",
      "\n",
      "Valid UUID userIds: 93 / 96\n",
      "\n",
      "3 rows with invalid userIds (will be filtered):\n",
      "  Row 17: \"\"tasks_in_usd\"\":3918.67...\n",
      "  Row 75: \"\"grade\"\":null...\n",
      "  Row 87: \"\"tasks_in_usd\"\":1593.36...\n"
     ]
    }
   ],
   "source": [
    "print(\"=== DATA VALIDATION ===\")\n",
    "print(f\"Total rows: {len(df_raw)}\")\n",
    "print(f\"Unique users (before validation): {df_raw['userId'].nunique()}\")\n",
    "print(f\"Unique sessions: {df_raw['sessionId'].nunique()}\")\n",
    "print()\n",
    "\n",
    "# Check for valid UUIDs (now without surrounding quotes)\n",
    "uuid_pattern = re.compile(r'^[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12}$')\n",
    "valid_users = df_raw['userId'].apply(lambda x: bool(uuid_pattern.match(str(x))))\n",
    "print(f\"Valid UUID userIds: {valid_users.sum()} / {len(df_raw)}\")\n",
    "\n",
    "if not valid_users.all():\n",
    "    print(f\"\\n{(~valid_users).sum()} rows with invalid userIds (will be filtered):\")\n",
    "    invalid_df = df_raw[~valid_users]\n",
    "    for idx, row in invalid_df.head(5).iterrows():\n",
    "        print(f\"  Row {idx}: {str(row['userId'])[:60]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "filter-valid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows after filtering invalid userIds: 93\n",
      "Unique users: 10\n"
     ]
    }
   ],
   "source": [
    "# Filter to valid rows only\n",
    "df = df_raw[valid_users].copy()\n",
    "print(f\"Rows after filtering invalid userIds: {len(df)}\")\n",
    "print(f\"Unique users: {df['userId'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "user-dist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== USER DISTRIBUTION ===\n",
      "userId\n",
      "c1d2a96d-da46-404b-97ed-ffcbd76f1dab    33\n",
      "66453e68-c05c-46b8-9e7a-71615370e110    27\n",
      "1927df39-3746-4a83-bf6d-527e91d72ee6    17\n",
      "0c4eee93-be4b-4afb-8049-31c2095fbd23    10\n",
      "98149010-b355-44ff-877a-c391a74da7fd     1\n",
      "e5c89a3b-b2db-428b-9ca5-2d59b9975f46     1\n",
      "fe5e1b7a-8b0e-4031-800d-3f6760f49558     1\n",
      "56e682af-dd66-4762-82d7-f3660d27af28     1\n",
      "39fb5e0b-6b41-4db0-b0c8-cfadcf61c343     1\n",
      "eb446d4d-edde-4618-8385-6b914fabd145     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Top 4 users account for 87/93 messages (93.5%)\n"
     ]
    }
   ],
   "source": [
    "print(\"=== USER DISTRIBUTION ===\")\n",
    "user_counts = df['userId'].value_counts()\n",
    "print(user_counts)\n",
    "print()\n",
    "print(f\"Top 4 users account for {user_counts.head(4).sum()}/{len(df)} messages ({user_counts.head(4).sum()/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-clean",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning & Type Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "clean-types",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model distribution:\n",
      "model\n",
      "unknown    60\n",
      "openai     33\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Convert timestamp to datetime\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], format='ISO8601', errors='coerce')\n",
    "\n",
    "# Parse tags JSON array\n",
    "def parse_tags(tags_str):\n",
    "    \"\"\"Parse JSON array of tags.\"\"\"\n",
    "    if pd.isna(tags_str) or tags_str == '':\n",
    "        return []\n",
    "    try:\n",
    "        return json.loads(tags_str)\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "df['tags_list'] = df['tags'].apply(parse_tags)\n",
    "\n",
    "# Extract model from tags (openai, anthropic, etc.)\n",
    "def extract_model(tags):\n",
    "    \"\"\"Extract AI model from tags.\"\"\"\n",
    "    for tag in tags:\n",
    "        tag_lower = str(tag).lower()\n",
    "        if 'openai' in tag_lower:\n",
    "            return 'openai'\n",
    "        if 'anthropic' in tag_lower or 'claude' in tag_lower:\n",
    "            return 'anthropic'\n",
    "    return 'unknown'\n",
    "\n",
    "df['model'] = df['tags_list'].apply(extract_model)\n",
    "\n",
    "print(\"Model distribution:\")\n",
    "print(df['model'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-input",
   "metadata": {},
   "source": [
    "## 4. Input Analysis & Separation\n",
    "\n",
    "Separate the user's **instruction** from any **data payload** (JSON) they're passing to Flora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "extract-instruction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs with JSON payload: 39 (41.9%)\n",
      "Inputs with @references: 4 (4.3%)\n"
     ]
    }
   ],
   "source": [
    "def extract_instruction_and_payload(text):\n",
    "    \"\"\"\n",
    "    Separate user instruction from data payload.\n",
    "    \n",
    "    Returns: (instruction, has_json_payload, has_reference)\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or text == '':\n",
    "        return ('', False, False)\n",
    "    \n",
    "    # Check for JSON payload (matches {...} patterns)\n",
    "    json_match = re.search(r'\\{[^{}]*(?:\\{[^{}]*\\}[^{}]*)*\\}', text)\n",
    "    has_json = json_match is not None\n",
    "    \n",
    "    # Check for @references (Flora-specific syntax like @work_period:uuid[Name])\n",
    "    ref_pattern = r'@\\w+:[a-f0-9-]+\\[[^\\]]+\\]'\n",
    "    has_reference = bool(re.search(ref_pattern, text))\n",
    "    \n",
    "    # Extract instruction (text before JSON or the whole text)\n",
    "    if has_json:\n",
    "        instruction = text[:json_match.start()].strip()\n",
    "    else:\n",
    "        instruction = text\n",
    "    \n",
    "    # Clean up instruction - replace @references with [REF] for cleaner analysis\n",
    "    instruction_clean = re.sub(ref_pattern, '[REF]', instruction)\n",
    "    \n",
    "    return (instruction_clean.strip(), has_json, has_reference)\n",
    "\n",
    "# Apply extraction\n",
    "extraction = df['input'].apply(extract_instruction_and_payload)\n",
    "df['instruction'] = extraction.apply(lambda x: x[0])\n",
    "df['has_json_payload'] = extraction.apply(lambda x: x[1])\n",
    "df['has_reference'] = extraction.apply(lambda x: x[2])\n",
    "\n",
    "print(f\"Inputs with JSON payload: {df['has_json_payload'].sum()} ({df['has_json_payload'].mean()*100:.1f}%)\")\n",
    "print(f\"Inputs with @references: {df['has_reference'].sum()} ({df['has_reference'].mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "preview-instructions",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SAMPLE INSTRUCTIONS (cleaned) ===\n",
      "1. For work period [REF]@parent:board:b1192a4c-f0fb-4fac-aa9a-17b284d95b8e[REBEL-Scrum] provide Executive Summary, Sprint R... [REF]\n",
      "\n",
      "2. Analyze the following data and provide a concise summary of the key findings. Keep your response in a short paragraph of... [JSON]\n",
      "\n",
      "3. tell me about this initiative\n",
      "\n",
      "4. provide sprint reto analysis for work period 'STAR-2025 SP23'\n",
      "\n",
      "5. Analyze the following data and provide a concise summary of the key findings. Keep your response in a short paragraph of... [JSON]\n",
      "\n",
      "6. what is the velocity for CS-Federal Bureau of Iteration for sprint 26\n",
      "\n",
      "7. Analyze the following data and provide a concise summary of the key findings. Keep your response in a short paragraph of... [JSON]\n",
      "\n",
      "8. what is the velocity for the last 6 sprints for CS-Federal Bureau of Iteration\n",
      "\n",
      "9. Analyze the following data and provide a concise summary of the key findings. Keep your response in a short paragraph of... [JSON]\n",
      "\n",
      "10. what is the velocity for the last six sprints for FBI team\n",
      "\n",
      "11. For work period 'REBEL-2025 SP26' provide Executive Summary, Sprint Retro Analysis, and Performance analysis\n",
      "\n",
      "12. Analyze the following data and provide a concise summary of the key findings. Keep your response in a short paragraph of... [JSON]\n",
      "\n",
      "13. Analyze the following data and provide a concise summary of the key findings. Keep your response in a short paragraph of... [JSON]\n",
      "\n",
      "14. how are my top 25 initiatives doing for deliverability\n",
      "\n",
      "15. for work period 'REBEL-2025 SP26' provide sprint retro analysis\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preview extracted instructions\n",
    "print(\"=== SAMPLE INSTRUCTIONS (cleaned) ===\")\n",
    "sample = df[df['instruction'] != ''].head(15)\n",
    "for i, (idx, row) in enumerate(sample.iterrows()):\n",
    "    instr = row['instruction'][:120]\n",
    "    flags = []\n",
    "    if row['has_json_payload']: flags.append('JSON')\n",
    "    if row['has_reference']: flags.append('REF')\n",
    "    flag_str = f\" [{', '.join(flags)}]\" if flags else \"\"\n",
    "    print(f\"{i+1}. {instr}...{flag_str}\" if len(row['instruction']) > 120 else f\"{i+1}. {instr}{flag_str}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-metrics",
   "metadata": {},
   "source": [
    "## 5. Compute Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "metrics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== METRICS SUMMARY ===\n",
      "Avg input length: 3283 chars\n",
      "Avg instruction length: 153 chars\n",
      "Avg messages per session: 1.27\n",
      "Avg sessions per user: 7.70\n",
      "Single-message sessions: 60 / 73 (82.2%)\n"
     ]
    }
   ],
   "source": [
    "# Text length metrics\n",
    "df['input_length'] = df['input'].str.len().fillna(0).astype(int)\n",
    "df['output_length'] = df['output'].str.len().fillna(0).astype(int)\n",
    "df['instruction_length'] = df['instruction'].str.len().fillna(0).astype(int)\n",
    "\n",
    "# Sort by session and timestamp\n",
    "df = df.sort_values(['sessionId', 'timestamp']).reset_index(drop=True)\n",
    "\n",
    "# Session metrics\n",
    "session_sizes = df.groupby('sessionId').size()\n",
    "df['session_message_count'] = df['sessionId'].map(session_sizes)\n",
    "\n",
    "# Is this the first message in session?\n",
    "df['is_first_in_session'] = ~df['sessionId'].duplicated(keep='first')\n",
    "\n",
    "# Message position within session (1st, 2nd, 3rd...)\n",
    "df['message_position'] = df.groupby('sessionId').cumcount() + 1\n",
    "\n",
    "# User metrics\n",
    "user_msg_counts = df.groupby('userId').size()\n",
    "df['user_total_messages'] = df['userId'].map(user_msg_counts)\n",
    "\n",
    "user_session_counts = df.groupby('userId')['sessionId'].nunique()\n",
    "df['user_session_count'] = df['userId'].map(user_session_counts)\n",
    "\n",
    "print(\"=== METRICS SUMMARY ===\")\n",
    "print(f\"Avg input length: {df['input_length'].mean():.0f} chars\")\n",
    "print(f\"Avg instruction length: {df['instruction_length'].mean():.0f} chars\")\n",
    "print(f\"Avg messages per session: {session_sizes.mean():.2f}\")\n",
    "print(f\"Avg sessions per user: {user_session_counts.mean():.2f}\")\n",
    "print(f\"Single-message sessions: {(session_sizes == 1).sum()} / {len(session_sizes)} ({(session_sizes == 1).mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-export",
   "metadata": {},
   "source": [
    "## 6. Export Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "export",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported 93 rows to ../data/flora-chats-cleaned.csv\n",
      "\n",
      "=== DATA SUMMARY ===\n",
      "total_messages: 93\n",
      "unique_users: 10\n",
      "unique_sessions: 73\n",
      "avg_session_depth: 1.27\n",
      "single_message_sessions_pct: 82.2\n",
      "pct_with_json_payload: 41.9\n",
      "pct_with_reference: 4.3\n",
      "first_message_date: 2025-12-10 19:58:44.193000+00:00\n",
      "last_message_date: 2026-01-09 17:10:56.745000+00:00\n",
      "model_distribution: {'unknown': 60, 'openai': 33}\n"
     ]
    }
   ],
   "source": [
    "# Select and order columns for export\n",
    "export_columns = [\n",
    "    'id', 'timestamp', 'userId', 'sessionId', 'environment',\n",
    "    'model', 'input', 'output', 'instruction',\n",
    "    'has_json_payload', 'has_reference',\n",
    "    'input_length', 'output_length', 'instruction_length',\n",
    "    'session_message_count', 'message_position', 'is_first_in_session',\n",
    "    'user_total_messages', 'user_session_count'\n",
    "]\n",
    "\n",
    "df_export = df[export_columns].copy()\n",
    "\n",
    "# Save cleaned data\n",
    "output_file = DATA_DIR / \"flora-chats-cleaned.csv\"\n",
    "df_export.to_csv(output_file, index=False)\n",
    "print(f\"Exported {len(df_export)} rows to {output_file}\")\n",
    "\n",
    "# Save data summary\n",
    "summary = {\n",
    "    'total_messages': len(df_export),\n",
    "    'unique_users': int(df_export['userId'].nunique()),\n",
    "    'unique_sessions': int(df_export['sessionId'].nunique()),\n",
    "    'avg_session_depth': round(float(session_sizes.mean()), 2),\n",
    "    'single_message_sessions_pct': round(float((session_sizes == 1).mean() * 100), 1),\n",
    "    'pct_with_json_payload': round(float(df_export['has_json_payload'].mean() * 100), 1),\n",
    "    'pct_with_reference': round(float(df_export['has_reference'].mean() * 100), 1),\n",
    "    'first_message_date': str(df_export['timestamp'].min()),\n",
    "    'last_message_date': str(df_export['timestamp'].max()),\n",
    "    'model_distribution': df_export['model'].value_counts().to_dict()\n",
    "}\n",
    "\n",
    "with open(DATA_DIR / 'data_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(\"\\n=== DATA SUMMARY ===\")\n",
    "for k, v in summary.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "final-preview",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CLEANED DATA PREVIEW ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>userId</th>\n",
       "      <th>instruction</th>\n",
       "      <th>has_json_payload</th>\n",
       "      <th>session_message_count</th>\n",
       "      <th>message_position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2026-01-09 16:29:38.196000+00:00</td>\n",
       "      <td>c1d2a96d-da46-404b-97ed-ffcbd76f1dab</td>\n",
       "      <td>Tell me about this initiative</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2026-01-07 19:14:37.562000+00:00</td>\n",
       "      <td>c1d2a96d-da46-404b-97ed-ffcbd76f1dab</td>\n",
       "      <td>For work period 'REBEL-2025 SP26' provide Exec...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-12-15 19:05:37.654000+00:00</td>\n",
       "      <td>66453e68-c05c-46b8-9e7a-71615370e110</td>\n",
       "      <td>Analyze the following data and provide a conci...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2026-01-05 16:43:30.135000+00:00</td>\n",
       "      <td>1927df39-3746-4a83-bf6d-527e91d72ee6</td>\n",
       "      <td>Analyze the following data and provide a conci...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2026-01-07 19:26:13.581000+00:00</td>\n",
       "      <td>1927df39-3746-4a83-bf6d-527e91d72ee6</td>\n",
       "      <td>Analyze the following data and provide a conci...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2026-01-09 16:57:51.458000+00:00</td>\n",
       "      <td>c1d2a96d-da46-404b-97ed-ffcbd76f1dab</td>\n",
       "      <td>tell me about this initiative</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-12-10 19:58:44.193000+00:00</td>\n",
       "      <td>66453e68-c05c-46b8-9e7a-71615370e110</td>\n",
       "      <td>Explain to me for BDC Tools the cycle time tre...</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-12-10 19:59:06.440000+00:00</td>\n",
       "      <td>66453e68-c05c-46b8-9e7a-71615370e110</td>\n",
       "      <td>Throughput and Velocity Comparisons</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2025-12-10 20:02:47.843000+00:00</td>\n",
       "      <td>66453e68-c05c-46b8-9e7a-71615370e110</td>\n",
       "      <td>Explain to me for the DSE board team the cycle...</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2025-12-16 22:23:22.235000+00:00</td>\n",
       "      <td>66453e68-c05c-46b8-9e7a-71615370e110</td>\n",
       "      <td>Analyze the following data and provide a conci...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         timestamp                                userId  \\\n",
       "0 2026-01-09 16:29:38.196000+00:00  c1d2a96d-da46-404b-97ed-ffcbd76f1dab   \n",
       "1 2026-01-07 19:14:37.562000+00:00  c1d2a96d-da46-404b-97ed-ffcbd76f1dab   \n",
       "2 2025-12-15 19:05:37.654000+00:00  66453e68-c05c-46b8-9e7a-71615370e110   \n",
       "3 2026-01-05 16:43:30.135000+00:00  1927df39-3746-4a83-bf6d-527e91d72ee6   \n",
       "4 2026-01-07 19:26:13.581000+00:00  1927df39-3746-4a83-bf6d-527e91d72ee6   \n",
       "5 2026-01-09 16:57:51.458000+00:00  c1d2a96d-da46-404b-97ed-ffcbd76f1dab   \n",
       "6 2025-12-10 19:58:44.193000+00:00  66453e68-c05c-46b8-9e7a-71615370e110   \n",
       "7 2025-12-10 19:59:06.440000+00:00  66453e68-c05c-46b8-9e7a-71615370e110   \n",
       "8 2025-12-10 20:02:47.843000+00:00  66453e68-c05c-46b8-9e7a-71615370e110   \n",
       "9 2025-12-16 22:23:22.235000+00:00  66453e68-c05c-46b8-9e7a-71615370e110   \n",
       "\n",
       "                                         instruction  has_json_payload  \\\n",
       "0                      Tell me about this initiative             False   \n",
       "1  For work period 'REBEL-2025 SP26' provide Exec...             False   \n",
       "2  Analyze the following data and provide a conci...              True   \n",
       "3  Analyze the following data and provide a conci...              True   \n",
       "4  Analyze the following data and provide a conci...              True   \n",
       "5                      tell me about this initiative             False   \n",
       "6  Explain to me for BDC Tools the cycle time tre...             False   \n",
       "7                Throughput and Velocity Comparisons             False   \n",
       "8  Explain to me for the DSE board team the cycle...             False   \n",
       "9  Analyze the following data and provide a conci...              True   \n",
       "\n",
       "   session_message_count  message_position  \n",
       "0                      1                 1  \n",
       "1                      1                 1  \n",
       "2                      1                 1  \n",
       "3                      1                 1  \n",
       "4                      1                 1  \n",
       "5                      1                 1  \n",
       "6                      3                 1  \n",
       "7                      3                 2  \n",
       "8                      3                 3  \n",
       "9                      1                 1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final data preview\n",
    "print(\"=== CLEANED DATA PREVIEW ===\")\n",
    "df_export[['timestamp', 'userId', 'instruction', 'has_json_payload', 'session_message_count', 'message_position']].head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
